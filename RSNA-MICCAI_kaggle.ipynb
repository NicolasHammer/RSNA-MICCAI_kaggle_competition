{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# RSNA-MICCAI Kaggle Competition"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The objective of this project is to predict the likelihood of MGMT promoter methylation given four types of structural multi-parametric MRI scans: \n",
                "- Fluid Attenuated Inversion Recovery (FLAIR)\n",
                "- T1-weighted pre-contrast (T1w)\n",
                "- T1-weighted post-contrast (T1Gd)\n",
                "- T2-weighted (T2)\n",
                "\n",
                "This is useful for predicing receptiveness to chemotherapy because the MGMT promoter fights against the agents used in chemotherapy.  When the MGMT promoter is methylated, the promoter is disabled, thereby making that system receptive to chemotherapy."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Let's First Explore the Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Importing relevant packages for EDA\n",
                "import os\n",
                "import math\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import KFold\n",
                "\n",
                "from PIL import Image\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## What is the Output?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As said in the introduction, the goal of our model is to predict the probability of methylation.  In the sample submission below, there is a list of BraTS2IDs with corresponding probabilities of 0.5 each."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
                "sample_submission.head(10)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "When training, we'll be given binary labels for the presence of MGMT promoter methylation."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "train_labels = pd.read_csv(\"data/train_labels.csv\")\n",
                "print(f\"{train_labels.shape[0] = }\")\n",
                "train_labels.head(10)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's look at the breakdown of patients with and without MGMT promoter methylation."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "with_methylation = (train_labels[\"MGMT_value\"] == 1).sum()\n",
                "without_methylation = train_labels.shape[0] - with_methylation\n",
                "print(f\"{with_methylation = }\")\n",
                "print(f\"{without_methylation = }\")\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## What is the Input?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "For each patient (who has an ID), we have four different types of multi-paramteric MRI scans.  Each MRI scan is a 3D scan broken down into a folder of 2D images.  To start, let's take a look at one image from one of the FLAIR training scans. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "patient_path = \"data/train/00002/\"\n",
                "mri_types = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]\n",
                "num_splits = 5\n",
                "splits = [x/(num_splits + 1) for x in range(1, num_splits + 1)]\n",
                "\n",
                "fig, ax = plt.subplots(num_splits, 4, figsize=(16, 16), tight_layout=True)\n",
                "for i, mri_type in enumerate(mri_types):\n",
                "    filenames = os.listdir(os.path.join(patient_path, mri_type))\n",
                "    print(f\"Number of {mri_type} Images = {len(filenames)}\")\n",
                "    for j, quartile in enumerate(splits):\n",
                "        filename = filenames[math.floor(len(filenames)*quartile)]\n",
                "\n",
                "        example_image = Image.open(\n",
                "            os.path.join(patient_path, mri_type, filename))\n",
                "\n",
                "        ax[j, i].imshow(example_image, cmap=\"gray\")\n",
                "        ax[j, i].set_axis_off()\n",
                "        if not j:\n",
                "            ax[j, i].set_title(mri_type, size=20)\n",
                "\n",
                "fig.suptitle(\"MRI Images of Patient 00002\", size=20)\n",
                "fig.show()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Data Management"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's add folder names to each row of the training labels."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "train_labels[\"imfolder\"] = [\"{0:05d}\".format(\n",
                "    id) for id in train_labels[\"BraTS21ID\"]]\n",
                "train_labels.head(10)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's add the number of MRI scans of each type for each patient."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "train_path = \"data/train\"\n",
                "train_labels = train_labels.reindex(\n",
                "    columns=train_labels.columns.tolist() + mri_types, fill_value=0)\n",
                "train_labels[mri_types] = train_labels[mri_types].astype(int)\n",
                "\n",
                "for i in train_labels.index:\n",
                "    for mri_type in mri_types:\n",
                "        train_labels.at[i, mri_type] = sum(len(files) for _, _, files in os.walk(\n",
                "            os.path.join(train_path, train_labels.at[i, \"imfolder\"], mri_type)))\n",
                "\n",
                "train_labels.head(10)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Unfortunately, it looks like the number of MRI images is not consistent across patients and MRI types.  Let's see how many patients have the same number of images across MRI types."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "num_allsame = sum([train_labels.at[i, \"FLAIR\"] == train_labels.at[i, \"T1w\"]\n",
                "                   == train_labels.at[i, \"T1wCE\"] == train_labels.at[i, \"T2w\"]\n",
                "                   for i in train_labels.index])\n",
                "print(f\"{num_allsame = }\")\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Based on these observations, it looks like we can't use a standard 3D ConvNet; rather, it would have to be a 2.5D ConvNet.  We can also try video classification with a 2D CNN/RNN combination."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Preprocessing and Splitting Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's split the folder data into features/targets and set up a KFold cross-validation object."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Establish hyperparameters pertaining to KFold\n",
                "N_SPLITS = 5\n",
                "RANDOM_STATE = 97"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "features = train_labels[\"imfolder\"].to_numpy(dtype=str)\n",
                "targets = train_labels[\"MGMT_value\"].to_numpy(dtype=np.float32)\n",
                "k_fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Video Classification Approach"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Import relevant packages for video classification\n",
                "import time\n",
                "import gc\n",
                "\n",
                "import torch\n",
                "from torch.nn import BCELoss\n",
                "from torch.optim import Adam\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "from src import video_model\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"{device = }\")\n",
                "\n",
                "#import importlib\n",
                "#importlib.reload(video_model)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's begin with the video classification approach by thinking about what shape we want our data to be in.  For every scan of a particular patient we want to process the entire sequence of images.  So, this would leave us with data of shape ```(num_images, 1, 224, 224)```.  As we saw in the EDA, the number of images is not constant across patient nor scan type, so ```num_images``` is variable.  In [src/video_model.py](src/video_model.py) you'll find the datset we use to create this shape."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Establish hyperparameters pertaining to the datasets\n",
                "IMAGE_SIZE = (224, 224)\n",
                "BATCH_SIZE = 1\n",
                "DIRECTORY = \"data/train/\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "video_training_dataset = video_model.VideoMRIDataset(\n",
                "    file_data=features, class_data=targets, directory=DIRECTORY, image_size=IMAGE_SIZE)\n",
                "\n",
                "example_sample, _ = video_training_dataset[17]\n",
                "print(f\"Patient id = {features[17]}\")\n",
                "print(\n",
                "    f\"Data shapes = { {mri_type: video.size() for mri_type, video in example_sample.items()} }\")\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now that we've seen some an example dataset, let's actually create a function to create the train and valid dataloaders given some data (which will be split in K-Fold cross validation)."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def video_create_dataloaders(train_features, train_targets, valid_features, valid_targets):\n",
                "    # Train data\n",
                "    video_train_dataset = video_model.VideoMRIDataset(\n",
                "        file_data=train_features, class_data=train_targets, directory=DIRECTORY, image_size=IMAGE_SIZE)\n",
                "    video_train_dataloader = DataLoader(\n",
                "        video_train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
                "\n",
                "    # valid data\n",
                "    video_valid_dataset = video_model.VideoMRIDataset(\n",
                "        file_data=valid_features, class_data=valid_targets, directory=DIRECTORY, image_size=IMAGE_SIZE)\n",
                "    video_valid_dataloader = DataLoader(\n",
                "        video_valid_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
                "\n",
                "    return video_train_dataloader, video_valid_dataloader\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's now create function to train and evaluate the model."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Train and Evaluate\n",
                "def train_function(model, train_dataloader, optimizer, criterion, learning_rate, epoch, device):\n",
                "    model.train()\n",
                "    total_loss = 0.\n",
                "    start_time = time.time()\n",
                "    log_interval = len(train_dataloader)//10\n",
                "\n",
                "    for batch_num, (scans, class_num) in enumerate(train_dataloader):\n",
                "        for mri_type, scan in scans.items():\n",
                "            scans[mri_type] = scan.to(device)\n",
                "        class_num = class_num.to(device)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        output = model(scans)\n",
                "\n",
                "        loss = criterion(output, class_num)\n",
                "        loss.backward()\n",
                "\n",
                "        optimizer.step()\n",
                "\n",
                "        total_loss += loss.item()\n",
                "        if batch_num % log_interval == 0 and batch_num > 0:\n",
                "            cur_loss = total_loss / log_interval\n",
                "            elapsed = time.time() - start_time\n",
                "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
                "                  'lr {:03.3f} | ms/batch {:5.2f} | '\n",
                "                  'loss {:5.5f}'.format(\n",
                "                      epoch, batch_num, len(\n",
                "                          train_dataloader.dataset) // train_dataloader.batch_size,\n",
                "                      learning_rate, elapsed * 1000 / log_interval,\n",
                "                      cur_loss))\n",
                "            total_loss = 0.\n",
                "            start_time = time.time()\n",
                "\n",
                "\n",
                "def evaluate(eval_model, valid_dataloader, criterion):\n",
                "    eval_model.eval()\n",
                "    num_correct = 0\n",
                "    total_loss = 0.\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for scans, class_num in valid_dataloader:\n",
                "            for mri_type, scan in scans.items():\n",
                "                scans[mri_type] = scan.to(device)\n",
                "            class_num = class_num.to(device)\n",
                "\n",
                "            output = eval_model(scans)\n",
                "            loss = criterion(output, class_num)\n",
                "\n",
                "            total_loss += loss.item()\n",
                "            num_correct += torch.sum(torch.eq(torch.round(output), class_num))\n",
                "\n",
                "    return num_correct / len(valid_dataloader.dataset), total_loss/len(valid_dataloader)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "We'll also need to make a funciton for the overall training process, as we are conducting k-fold cross-validation."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Establish hyperparamters pertaining to the training of the model\n",
                "EPOCHS = 10\n",
                "LEARNING_RATE = 0.001\n",
                "LSTM_UNITS = 256\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Function to run through training process\n",
                "def training_process(epochs, train_dataloader, valid_dataloader, device, learning_rate):\n",
                "    model = video_model.VideoMRIEnsemble(mri_types, LSTM_UNITS).to(device)\n",
                "    criterion = BCELoss()\n",
                "    optimizer = Adam(model.parameters(), LEARNING_RATE)\n",
                "\n",
                "    best_accuracy = 0.\n",
                "    best_model = None\n",
                "    accuracy_list, valid_loss_list = [], []\n",
                "\n",
                "    for epoch in range(1, epochs + 1):\n",
                "        epoch_start_time = time.time()\n",
                "        train_function(model, train_dataloader, optimizer,\n",
                "                       criterion, learning_rate, epoch, device)\n",
                "        accuracy, loss = evaluate(model, valid_dataloader, criterion)\n",
                "        print('-'*89)\n",
                "        print('| end of epoch {:3d} | time: {:5.2f}s | validation accuracy {:2.3f}% | '\n",
                "              'valid loss {:5.5f}'.format(\n",
                "            epoch, (time.time() - epoch_start_time), accuracy*100, loss))\n",
                "        print('-'*89)\n",
                "\n",
                "        accuracy_list.append(accuracy)\n",
                "        valid_loss_list.append(loss)\n",
                "\n",
                "        if accuracy > best_accuracy:\n",
                "            best_accuracy = accuracy\n",
                "            best_model = model\n",
                "\n",
                "    return best_model, accuracy_list, valid_loss_list\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In each iteration our top level code will:\n",
                "- Split thedata into train and valid indices\n",
                "- Create the respective dataloaders\n",
                "- train the model for ```EPOCHS``` number of epochs\n",
                "- store a list of the validation accuracy and average validation loss "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Run through entire KFold process\n",
                "gc.collect()\n",
                "torch.cuda.empty_cache()\n",
                "\n",
                "accuracy_list, valid_loss_list = [], []\n",
                "for i, (train_indices, valid_indices) in enumerate(k_fold.split(features)):\n",
                "    print('='*89)\n",
                "    print(f\"Fold {i+1}/{N_SPLITS}\")\n",
                "    print('='*89)\n",
                "\n",
                "    train_features, valid_features = features[train_indices], features[valid_indices]\n",
                "    train_targets, valid_targets = targets[train_indices], targets[valid_indices]\n",
                "\n",
                "    video_train_dataloader, video_valid_dataloader = video_create_dataloaders(\n",
                "        train_features, train_targets, valid_features, valid_targets)\n",
                "\n",
                "    _, accuracy_temp, valid_temp = training_process(\n",
                "        EPOCHS, video_train_dataloader, video_valid_dataloader, device, LEARNING_RATE)\n",
                "    accuracy_list.append(accuracy_temp)\n",
                "    valid_loss_list.append(valid_temp)\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.6 64-bit ('.env': venv)"
        },
        "interpreter": {
            "hash": "d0243063896cc0741dc2bd84024b1fddce5c5cb36ab3e12b5cb48af2be3c3430"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}